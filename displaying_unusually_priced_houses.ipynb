{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72d1af36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display abnormal ID (KMeans): [689213 736447 810825 873233]\n",
      "Display abnormal ID (IsolationForest): [689213 844167 670385 810825 873233]\n",
      "Display abnormal ID (OneClassSVM): [689213 788565 810825 873233]\n",
      "Display abnormal ID (Simultaneously): [689213 810825 873233]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yoshi\\AppData\\Local\\Temp/ipykernel_16120/947982100.py:47: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  distance = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def decoy_property_detection(csv):\n",
    "    df_original = pd.read_csv(csv)\n",
    "    df = df_original.copy()\n",
    "    \n",
    "    # Reduce the impact of extremely high prices and long time to station on classification\n",
    "    df = df.drop(df[(df['price_per_tsubo'] > df['price_per_tsubo'].quantile(q=0.75))].index)\n",
    "    df = df.drop(df[(df['minute_to_station'] > df['minute_to_station'].quantile(q=0.95))].index)\n",
    "    \n",
    "    # Encode target labels with value\n",
    "    labelencoder = LabelEncoder()\n",
    "    df['land_shape'] = labelencoder.fit_transform(df['land_shape'])\n",
    "    df['frontal_road_direction'] = labelencoder.fit_transform(df['frontal_road_direction'])\n",
    "    df['frontal_road_kind'] = labelencoder.fit_transform(df['frontal_road_kind'])\n",
    "    \n",
    "    data = df[['price_per_tsubo', 'minute_to_station', 'land_space', 'land_shape']]\n",
    "    X = data.values\n",
    "\n",
    "    # Standardization processing, mean is 0, standard deviation is 1\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    data = pd.DataFrame(X_std)\n",
    "\n",
    "    # Reduce feature dimension to 2\n",
    "    pca = PCA(n_components=3)\n",
    "    data = pca.fit_transform(data)\n",
    "\n",
    "    # Normalize the 2 new features after dimensionality reduction\n",
    "    scaler = StandardScaler()\n",
    "    np_scaled = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(np_scaled)\n",
    "\n",
    "    # Train KMeans\n",
    "    df['cluster'] = KMeans(n_clusters=3).fit_predict(data)\n",
    "    df.index = data.index\n",
    "    df['principal_feature1'] = data[0]\n",
    "    df['principal_feature2'] = data[1]\n",
    "\n",
    "    def get_distance_point(data, model):\n",
    "        distance = pd.Series()\n",
    "        for i in range(0,len(data)):\n",
    "            Xa = np.array(data.loc[i])\n",
    "            Xb = model.cluster_centers_[model.labels_[i]]\n",
    "            distance.at[i] = np.linalg.norm(Xa-Xb)\n",
    "        return distance\n",
    "\n",
    "    # Set the outlier scale\n",
    "    outliers_fraction = 0.05\n",
    "\n",
    "    # To get the distance from each point to the cluster center\n",
    "    distance = get_distance_point(data, KMeans(n_clusters=3).fit(data))\n",
    "\n",
    "    # Calculate the number of outliers based on the outliers_fraction and set a threshold for outliers\n",
    "    threshold = distance.nlargest(int(outliers_fraction*len(distance))).min()\n",
    "\n",
    "    # Judging whether it is an abnormal value according to the threshold\n",
    "    df['anomaly_KMeans'] = (distance >= threshold).astype(int)\n",
    "\n",
    "    # Train isolation forest\n",
    "    model =  IsolationForest(contamination = outliers_fraction)\n",
    "    model.fit(data)\n",
    "    df['anomaly_IsolationForest'] = pd.Series(model.predict(data))\n",
    "    \n",
    "    # Train OneClassSVM\n",
    "    model = OneClassSVM(nu=outliers_fraction, kernel=\"rbf\", gamma=0.01)\n",
    "    model.fit(data)\n",
    "    df['anomaly_OneClassSVM'] = pd.Series(model.predict(data))\n",
    "    \n",
    "    # Display exception ID\n",
    "    print('Display abnormal ID (KMeans):',df.loc[df['anomaly_KMeans'] == 1]['id'].values)\n",
    "    print('Display abnormal ID (IsolationForest):',df.loc[df['anomaly_IsolationForest'] == -1]['id'].values)\n",
    "    print('Display abnormal ID (OneClassSVM):',df.loc[df['anomaly_OneClassSVM'] == -1]['id'].values)\n",
    "    print('Display abnormal ID (Simultaneously):',df.loc[(df.anomaly_KMeans == 1) & (df.anomaly_IsolationForest == -1 ) & (df.anomaly_OneClassSVM == -1 )]['id'].values)\n",
    "    \n",
    "\n",
    "    \n",
    "decoy_property_detection('d_bukken_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f07c57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
